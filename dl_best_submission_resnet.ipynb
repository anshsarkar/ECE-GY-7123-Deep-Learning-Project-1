{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the necessary libraries for the project\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.optim import Adam\n",
    "from collections import defaultdict\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from typing import Any, Callable, Optional, Tuple, Union\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seed values for reproducibility\n",
    "\n",
    "seed = 1029\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "# some cudnn methods can be random even after fixing the seed\n",
    "# unless you tell it to be deterministic\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Parameters and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining variables, parameters and hyperparameters for the run\n",
    "\n",
    "run_on_kaggle = 1                           # Set this to 1 if running on Kaggle, 0 if running on local machine\n",
    "\n",
    "# Setting up the data directories and model save path based on the run environment\n",
    "if run_on_kaggle:\n",
    "    train_data_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python'\n",
    "    val_data_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python'\n",
    "    test_data_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\n",
    "    model_save_path = './'\n",
    "    num_of_workers = 16\n",
    "    download_data = False\n",
    "\n",
    "else:\n",
    "    base_dir = './data'\n",
    "    train_data_dir = './data/cifar-10-batches-py'\n",
    "    val_data_dir = './data/cifar-10-batches-py'\n",
    "    test_data_dir = './data/cifar_test_nolabel.pkl'\n",
    "    model_save_path = './checkpoint'\n",
    "    num_of_workers = 0\n",
    "    download_data = False\n",
    "\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "    \n",
    "    if not os.path.exists(model_save_path):\n",
    "        os.makedirs(model_save_path)\n",
    "    \n",
    "    if not os.path.exists(train_data_dir):\n",
    "        download_data = True\n",
    "        train_data_dir = './data'\n",
    "        val_data_dir = './data'\n",
    "    \n",
    "    if not os.path.exists(val_data_dir):\n",
    "        download_data = True\n",
    "    \n",
    "    if not os.path.exists(test_data_dir):\n",
    "       print(\"No Label Test Data not found\")\n",
    "\n",
    "\n",
    "# Defining Parameters and Hyperparameters\n",
    "train_batch_size = 128\n",
    "val_batch_size = 100\n",
    "test_batch_size = 100\n",
    "num_epochs = 200\n",
    "learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "cosine_annealing_T_max = num_epochs\n",
    "\n",
    "\n",
    "# Defining Model Configurations and Techniques\n",
    "use_cutout = 1                              # Set this to 1 if using Cutout, 0 if not using Cutout\n",
    "use_mixup = 0                               # Set this to 1 if using Mixup, 0 if not using Mixup\n",
    "use_label_smoothing = 1                     # Set this to 1 if using Label Smoothing, 0 if not using Label Smoothing\n",
    "use_lookahead = 1                           # Set this to 1 if using Lookahead, 0 if not using Lookahead\n",
    "\n",
    "\n",
    "if use_cutout:\n",
    "    cutout_n_holes = 1\n",
    "    cutout_length = 8\n",
    "\n",
    "if use_mixup:\n",
    "    mixup_alpha = 0.75\n",
    "\n",
    "if use_label_smoothing:\n",
    "    label_smoothing_epsilon = 0.2\n",
    "\n",
    "if use_lookahead:\n",
    "    lookahead_k = 5\n",
    "    lookahead_alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutout Implementation for Data Augmentation\n",
    "class Cutout(object):\n",
    "    \"\"\"Randomly mask out one or more patches from an image.\n",
    "\n",
    "    Args:\n",
    "        n_holes (int): Number of patches to cut out of each image.\n",
    "        length (int): The length (in pixels) of each square patch.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_holes, length):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Tensor): Tensor image of size (C, H, W).\n",
    "        Returns:\n",
    "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
    "        \"\"\"\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "\n",
    "        for n in range(self.n_holes):\n",
    "            y = np.random.randint(h)\n",
    "            x = np.random.randint(w)\n",
    "\n",
    "            y1 = np.clip(y - self.length // 2, 0, h)\n",
    "            y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x - self.length // 2, 0, w)\n",
    "            x2 = np.clip(x + self.length // 2, 0, w)\n",
    "\n",
    "            mask[y1: y2, x1: x2] = 0.\n",
    "\n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = mask.expand_as(img)\n",
    "        img = img * mask\n",
    "\n",
    "        return img\n",
    "\n",
    "def prepare_data(train_data_dir, val_data_dir):\n",
    "    '''\n",
    "    Function to prepare the data for training and validation. This will return the train and validation loader.\n",
    "    It will also apply data augmentation and data normalization to the data.\n",
    "    '''\n",
    "\n",
    "    # Data Augmentation and Transformation for the Training Data\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    # Data Transformation with Cutout for the Training Data\n",
    "    train_transform_cutout = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        Cutout(n_holes=cutout_n_holes, length=cutout_length)\n",
    "    ])\n",
    "\n",
    "    # Data Augmentation and Transformation for the Validation Data\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    if use_cutout:\n",
    "        final_train_transform = train_transform_cutout\n",
    "    else:\n",
    "        final_train_transform = train_transform\n",
    "\n",
    "    # Loading the CIFAR-10 Training and Validation Data\n",
    "    train_dataset = torchvision.datasets.CIFAR10(root=train_data_dir, train=True, download=download_data, transform=final_train_transform)\n",
    "    val_dataset = torchvision.datasets.CIFAR10(root=val_data_dir, train=False, download=download_data, transform=val_transform)\n",
    "\n",
    "    # Creating the Data Loaders for Training and Validation\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=num_of_workers)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=val_batch_size, shuffle=False, num_workers=num_of_workers)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, kernel=3, shortcut_kernel=1, dropout = 0.0):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        # First convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        # Second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Shortcut connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != self.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size=shortcut_kernel, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply first convolution, batch norm, and ReLU\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        # Apply second convolution and batch norm\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        # Add shortcut connection\n",
    "        out += self.shortcut(x)\n",
    "        # Apply final ReLU\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, channels, strides, kernel_size, shortcut_kernel_size, pool_size, dropout, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = channels[0]\n",
    "        self.kernel_size = kernel_size\n",
    "        self.shortcut_kernel_size = shortcut_kernel_size\n",
    "        self.pool_size = pool_size\n",
    "\n",
    "        # Initial convolution layer\n",
    "        self.conv1 = nn.Conv2d(3, channels[0], kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(channels[0])\n",
    "\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(num_blocks)):\n",
    "            self.layers.append(\n",
    "                self._make_layer(block[i], channels[i], num_blocks[i], stride=strides[i], dropout = dropout)\n",
    "            )\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.linear = nn.Linear(channels[-1] * block[-1].expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride, dropout):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)  # First block uses the specified stride, others use stride=1\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride, self.kernel_size, self.shortcut_kernel_size, dropout))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply initial convolution, batch norm, and ReLU\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        # Pass through all layers\n",
    "        for layer in self.layers:\n",
    "            out = layer(out)\n",
    "\n",
    "        # Apply average pooling and flatten\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "\n",
    "        # Apply fully connected layer\n",
    "        out = self.dropout(out)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the ResNet Model Architecture\n",
    "type_of_block_used = [BasicBlock, BasicBlock, BasicBlock]\n",
    "num_of_blocks = [4, 5, 3]\n",
    "num_of_channels = [64, 128, 256]\n",
    "strides_per_block = [1, 2, 2]\n",
    "kernel_size = 3\n",
    "shortcut_kernel_size = 1\n",
    "pool_size = 8\n",
    "dropout = 0.0\n",
    "\n",
    "# Creating the ResNet Model\n",
    "model = ResNet(type_of_block_used, num_of_blocks, num_of_channels, strides_per_block, kernel_size, shortcut_kernel_size, pool_size, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the model summary and total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "if total_params > 5000000:\n",
    "    raise Exception(\"Model size exceeds 5 million parameters\")\n",
    "\n",
    "# Checking the model summary\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added Lookahead Optimizer\n",
    "class Lookahead(Optimizer):\n",
    "    def __init__(self, base_optimizer, alpha=0.5, k=6):\n",
    "        if not 0.0 <= alpha <= 1.0:\n",
    "            raise ValueError(f'Invalid slow update rate: {alpha}')\n",
    "        if not 1 <= k:\n",
    "            raise ValueError(f'Invalid lookahead steps: {k}')\n",
    "        defaults = dict(lookahead_alpha=alpha, lookahead_k=k, lookahead_step=0)\n",
    "        self.base_optimizer = base_optimizer\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "        self.defaults = base_optimizer.defaults\n",
    "        self.defaults.update(defaults)\n",
    "        self.state = defaultdict(dict)\n",
    "        # manually add our defaults to the param groups\n",
    "        for name, default in defaults.items():\n",
    "            for group in self.param_groups:\n",
    "                group.setdefault(name, default)\n",
    "\n",
    "    def update_slow(self, group):\n",
    "        for fast_p in group[\"params\"]:\n",
    "            if fast_p.grad is None:\n",
    "                continue\n",
    "            param_state = self.state[fast_p]\n",
    "            if 'slow_buffer' not in param_state:\n",
    "                param_state['slow_buffer'] = torch.empty_like(fast_p.data)\n",
    "                param_state['slow_buffer'].copy_(fast_p.data)\n",
    "            slow = param_state['slow_buffer']\n",
    "            slow.add_(group['lookahead_alpha'], fast_p.data - slow)\n",
    "            fast_p.data.copy_(slow)\n",
    "\n",
    "    def sync_lookahead(self):\n",
    "        for group in self.param_groups:\n",
    "            self.update_slow(group)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        # print(self.k)\n",
    "        #assert id(self.param_groups) == id(self.base_optimizer.param_groups)\n",
    "        loss = self.base_optimizer.step(closure)\n",
    "        for group in self.param_groups:\n",
    "            group['lookahead_step'] += 1\n",
    "            if group['lookahead_step'] % group['lookahead_k'] == 0:\n",
    "                self.update_slow(group)\n",
    "        return loss\n",
    "\n",
    "    def state_dict(self):\n",
    "        fast_state_dict = self.base_optimizer.state_dict()\n",
    "        slow_state = {\n",
    "            (id(k) if isinstance(k, torch.Tensor) else k): v\n",
    "            for k, v in self.state.items()\n",
    "        }\n",
    "        fast_state = fast_state_dict['state']\n",
    "        param_groups = fast_state_dict['param_groups']\n",
    "        return {\n",
    "            'state': fast_state,\n",
    "            'slow_state': slow_state,\n",
    "            'param_groups': param_groups,\n",
    "        }\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        fast_state_dict = {\n",
    "            'state': state_dict['state'],\n",
    "            'param_groups': state_dict['param_groups'],\n",
    "        }\n",
    "        self.base_optimizer.load_state_dict(fast_state_dict)\n",
    "\n",
    "        # We want to restore the slow state, but share param_groups reference\n",
    "        # with base_optimizer. This is a bit redundant but least code\n",
    "        slow_state_new = False\n",
    "        if 'slow_state' not in state_dict:\n",
    "            print('Loading state_dict from optimizer without Lookahead applied.')\n",
    "            state_dict['slow_state'] = defaultdict(dict)\n",
    "            slow_state_new = True\n",
    "        slow_state_dict = {\n",
    "            'state': state_dict['slow_state'],\n",
    "            'param_groups': state_dict['param_groups'],  # this is pointless but saves code\n",
    "        }\n",
    "        super(Lookahead, self).load_state_dict(slow_state_dict)\n",
    "        self.param_groups = self.base_optimizer.param_groups  # make both ref same container\n",
    "        if slow_state_new:\n",
    "            # reapply defaults to catch missing lookahead specific ones\n",
    "            for name, default in self.defaults.items():\n",
    "                for group in self.param_groups:\n",
    "                    group.setdefault(name, default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=32):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "  \n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Label Smoothing Cross Entropy Loss\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, eps=0.05, reduction='mean'):\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        if self.reduction=='sum':\n",
    "            loss = -log_preds.sum()\n",
    "        else:\n",
    "            loss = -log_preds.sum(dim=-1)\n",
    "            if self.reduction=='mean':\n",
    "                loss = loss.mean()\n",
    "        return loss*self.eps/c + (1-self.eps) * F.nll_loss(log_preds, target, reduction=self.reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gradient_norms(model):\n",
    "    total_norm = 0.0\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            param_norm = p.grad.data.norm(2)  # L2 norm of gradients\n",
    "            total_norm += param_norm.item() ** 2\n",
    "    total_norm = total_norm ** (1.0 / 2)  # Total L2 norm\n",
    "    return total_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining lists to store the training and validation losses, accuracies and gradient norms to plot later\n",
    "train_losses = []\n",
    "gradients_norms = []\n",
    "train_acc = []\n",
    "test_losses_l1 = []\n",
    "test_acc_l1 = []\n",
    "plot_train_loss = []\n",
    "plot_test_loss = []\n",
    "plot_gradient_norms = []\n",
    "\n",
    "best_acc = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_for_one_epoch(model, device, train_loader, optimizer):\n",
    "    model.to(device)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    pbar = tqdm(train_loader)\n",
    "\n",
    "    correct = 0\n",
    "    processed = 0\n",
    "    train_loss_accu = 0\n",
    "    grad_norm_accu = 0\n",
    "\n",
    "    # Choose the loss function based on whether label smoothing is enabled\n",
    "    if use_label_smoothing:\n",
    "        criterion = LabelSmoothingCrossEntropy(eps=label_smoothing_epsilon)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Iterate over the training data in batches\n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Apply mixup augmentation if enabled\n",
    "        if use_mixup:\n",
    "            data, targets_a, targets_b, lam = mixup_data(data, target, mixup_alpha)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(data)\n",
    "\n",
    "        # Compute the loss based on whether mixup is enabled\n",
    "        if use_mixup:\n",
    "            loss = mixup_criterion(criterion, y_pred, targets_a, targets_b, lam)\n",
    "        else:\n",
    "            loss = criterion(y_pred, target)\n",
    "\n",
    "        # Accumulate the loss for the epoch\n",
    "        train_loss_accu += loss.item()\n",
    "        # Append the current loss to the list of training losses\n",
    "        train_losses.append(loss)\n",
    "\n",
    "        # Backward pass: compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Accumulate gradient norms and append to the list of gradient norms\n",
    "        grad_norm_accu += check_gradient_norms(model)\n",
    "        gradients_norms.append(check_gradient_norms(model))\n",
    "\n",
    "        # Update model parameters using the optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute predictions and update accuracy counters\n",
    "        pred = y_pred.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        processed += len(data)\n",
    "        \n",
    "        pbar.set_description(desc= f'Loss={loss.item()}\\tAccuracy={100*correct/processed:0.2f}\\tGradient Norm={grad_norm_accu/(batch_idx+1):0.2f}')\n",
    "\n",
    "    # Append the epoch's accuracy, average loss, and average gradient norm to their respective lists\n",
    "    train_acc.append(100*correct/processed)\n",
    "    plot_train_loss.append(train_loss_accu/len(train_loader))\n",
    "    plot_gradient_norms.append(grad_norm_accu/len(train_loader))\n",
    "\n",
    "    # Print the epoch's average loss, accuracy, and gradient norm\n",
    "    print(f'Epoch Loss = {train_loss_accu/len(train_loader)} \\t Epoch Accuracy = {100*correct/processed:0.2f} \\t Gradient Norm = {grad_norm_accu/len(train_loader):0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model ,device, test_loader):\n",
    "    model.eval()\n",
    "    average_test_loss = 0\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    global best_acc\n",
    "\n",
    "    # Choose the loss function based on whether label smoothing is enabled\n",
    "    if use_label_smoothing:\n",
    "        criterion = LabelSmoothingCrossEntropy(eps=label_smoothing_epsilon)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Iterate over the validation data in batches for inference\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    # Calculate the average loss and accuracy for the validation data and print the results\n",
    "    average_test_loss = test_loss/len(test_loader.dataset)\n",
    "    test_losses_l1.append(average_test_loss)\n",
    "\n",
    "    print(\"Validation Metrics: Average Loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\".format(\n",
    "        average_test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "    test_acc_l1.append(100. * correct / len(test_loader.dataset))\n",
    "\n",
    "    # Save the model if the current accuracy is the best so far\n",
    "    if 100. * correct / len(test_loader.dataset) > best_acc:\n",
    "        best_acc = 100. * correct / len(test_loader.dataset)\n",
    "        model.cpu()\n",
    "        model_scripted = torch.jit.script(model)\n",
    "        model_scripted.save(os.path.join(model_save_path, 'best_model.pt'))\n",
    "        print(f\"Model saved with accuracy {best_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device):\n",
    "\n",
    "    print(\"Preparing Data\")\n",
    "    train_loader, val_loader = prepare_data(train_data_dir, val_data_dir)\n",
    "\n",
    "    # Choose the optimizer based on whether lookahead is enabled\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "    if use_lookahead:\n",
    "        optimizer = Lookahead(optimizer, alpha=lookahead_alpha, k=lookahead_k)\n",
    "\n",
    "    # Scheduler for Cosine Annealing\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cosine_annealing_T_max)\n",
    "    \n",
    "    # Train the model for the specified number of epochs\n",
    "    \n",
    "    print(\"Starting Training\")\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        train_for_one_epoch(model, device, train_loader, optimizer)\n",
    "        evaluate(model, device, val_loader)\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data for plotting the training and validation losses, accuracies and gradient norms\n",
    "arr_train=np.array(torch.Tensor(train_losses).cpu())\n",
    "arr_test=np.array(torch.Tensor(test_losses_l1).cpu())\n",
    "arr_train_acc=np.array(torch.Tensor(train_acc).cpu())\n",
    "arr_test_acc=np.array(torch.Tensor(test_acc_l1).cpu())\n",
    "gradients_norms_int = np.array(torch.Tensor(gradients_norms).cpu())\n",
    "plot_train_loss_fin = np.array(torch.Tensor(plot_train_loss).cpu())\n",
    "plot_gd_norm_fin = np.array(torch.Tensor(plot_gradient_norms).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(arr_train_acc)\n",
    "plt.plot(arr_test_acc)\n",
    "plt.legend([\"train\",\"test\"])\n",
    "plt.title(\"Epoch vs Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(plot_gd_norm_fin)\n",
    "# plt.plot(arr_test)\n",
    "plt.legend([\"train\"])\n",
    "plt.title(\"Epoch vs GD\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(plot_train_loss_fin)\n",
    "# plt.plot(arr_test)\n",
    "plt.legend([\"train\"])\n",
    "plt.title(\"Epoch vs Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(arr_train1)\n",
    "plt.plot(arr_test)\n",
    "plt.legend([\"test\"])\n",
    "plt.title(\"Epoch vs Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(os.path.join(model_save_path, 'best_model.pt'), weights_only = False)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Test Data Loader\n",
    "\n",
    "class Cifar10NoLabelDataset(VisionDataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: Union[str, Path],\n",
    "        transform: Optional[Callable] = None\n",
    "    ) -> None:\n",
    "        \n",
    "        super().__init__(root, transform=transform, target_transform=None)\n",
    "\n",
    "        self.data: Any = []\n",
    "        self.targets = []\n",
    "        \n",
    "        with open(root, 'rb') as fo:\n",
    "            batch = pickle.load(fo, encoding='bytes')\n",
    "\n",
    "        \n",
    "        self.data = batch[b'data']\n",
    "        self.targets = batch[b'ids']\n",
    "        # self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n",
    "        # self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tranform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "test_data_no_label = Cifar10NoLabelDataset(test_data_dir, transform=test_tranform)\n",
    "test_loader_no_label = torch.utils.data.DataLoader(test_data_no_label, batch_size=test_batch_size, shuffle=False, num_workers=num_of_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "predictions = []\n",
    "for batch_idx, (inputs,index) in enumerate(test_loader_no_label):\n",
    "        inputs, index = inputs.to(device), index.to(device)\n",
    "        indexes.extend(index.cpu().tolist())\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(torch.tensor(predicted).cpu().tolist())\n",
    "        \n",
    "\n",
    "dictionary = {'ID':indexes,'Label':predictions}\n",
    "print(len(indexes))\n",
    "print(len(predictions))\n",
    "\n",
    "df = pd.DataFrame(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(test_data_no_label.data[i])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('out.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
